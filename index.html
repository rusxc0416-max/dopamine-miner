<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>OD | NEURAL SYNC TEST</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        body { margin: 0; background: #000; color: #333; font-family: monospace; overflow: hidden; }
        #webcam { position: fixed; opacity: 0.1; width: 200px; transform: scaleX(-1); } /* 隐藏自己的画面 */
        #status-ui { position: fixed; top: 20px; left: 20px; font-size: 12px; z-index: 100; color: #0f0; }
        #video-container { width: 100vw; height: 100vh; display: flex; justify-content: center; align-items: center; }
        video#main-display { width: 100%; height: 100%; object-fit: cover; }
    </style>
</head>
<body>

<div id="status-ui">
    [ SYSTEM: STABLE ]<br>
    [ EMOTION_SYNC: <span id="emotion">DETECTING...</span> ]
</div>

<video id="webcam" autoplay muted></video>

<div id="video-container">
    <video id="main-display" loop muted>
        <source src="od_fear_loop.mp4" type="video/mp4">
    </video>
</div>

<script>
    const webcam = document.getElementById('webcam');
    const emotionText = document.getElementById('emotion');
    const mainVideo = document.getElementById('main-display');

    // 1. 加载 AI 模型（从官方 GitHub CDN 加载）
    async function loadModels() {
        const MODEL_URL = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights';
        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
        await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
        startWebcam();
    }

    // 2. 开启摄像头
    function startWebcam() {
        navigator.mediaDevices.getUserMedia({ video: {} })
            .then(stream => { webcam.srcObject = stream; })
            .catch(err => console.error("Access Denied", err));
    }

    // 3. 核心交互逻辑：表情识别与视频反馈
    webcam.addEventListener('play', () => {
        setInterval(async () => {
            const detections = await faceapi.detectAllFaces(webcam, new faceapi.TinyFaceDetectorOptions())
                .withFaceExpressions();

            if (detections.length > 0) {
                const emotions = detections[0].expressions;
                const topEmotion = Object.keys(emotions).reduce((a, b) => emotions[a] > emotions[b] ? a : b);
                
                emotionText.innerText = topEmotion.toUpperCase();

                // 小岛秀夫式交互：如果你在笑（happy）
                if (topEmotion === 'happy' && emotions.happy > 0.6) {
                    switchToCreepySmile();
                } else {
                    returnToFear();
                }
            }
        }, 200); // 每 200 毫秒检测一次
    });

    function switchToCreepySmile() {
        // 这里的逻辑是：当你笑的时候，切换视频源
        // 如果你只有一张图，可以改成显示刚才生成的那个红色眼睛的效果
        document.body.style.backgroundColor = '#1a0000';
        emotionText.style.color = 'red';
        emotionText.innerText = "SMILE DETECTED: WHY ARE YOU LAUGHING?";
        // mainVideo.src = 'creepy_smile.mp4';
    }

    function returnToFear() {
        document.body.style.backgroundColor = '#000';
        emotionText.style.color = '#0f0';
    }

    loadModels();
</script>
</body>
</html>